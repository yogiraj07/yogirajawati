package custom.mr.utils;

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Enumeration;
import java.util.HashSet;
import java.util.Hashtable;
import java.util.List;
import java.util.zip.GZIPInputStream;

import custom.mr.Context;
import custom.mr.IntWritable;
import custom.mr.Job;
import custom.mr.Mapper;
import custom.mr.Reducer;
import custom.mr.Text;

public class FileIO<KEYIN, VALUEIN, KEYOUT, VALUEOUT>
{
	public Job jobObj = new Job();
	
	public void fetchMapperInput(String mainClassForRun, String ipLocalFolder, String outputFolderName)
	{
		Context context = new Context(outputFolderName, true);	// Output folder name
		File folder = new File(ipLocalFolder);
		for (final File fileEntry : folder.listFiles()) 
		{
			if(fileEntry.getName().equals("index.html"))
				continue;
			
	        try 
	        {
	        	String filePath = ipLocalFolder + "/" + fileEntry.getName();
				
	        	if(filePath.contains(".tar"))
	        	{
	        		GZIPInputStream gzip = null;
	        		
	        	}else
	        	{
	        		BufferedReader reader = new BufferedReader(new FileReader(filePath));
	        	}
				System.out.println("Fetching from: " + filePath + " and running mapper on it.");
				String ipLine;
				
				while(null != (ipLine = reader.readLine()))
				{
					Mapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT> obj = (Mapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT>)Class.forName(mainClassForRun).newInstance();
					obj.map(fileEntry.getName(), new Text(ipLine), context);					
				}
				
				System.out.println("Mapper finished on " + filePath);
				
				reader.close();
			} catch (Exception e) 
	        {
				e.printStackTrace();
			}  
	    }
	}
	
	
	
	public void reduceOnEachKey(String reducerClass, String keyFileName, String key, int clusterId)
	{
		try 
	    {
			ArrayList<IntWritable> valList = new ArrayList<>();
			Context context = new Context("/tmp/part-" + clusterId, false);	// Output folder name
			//Class<?> ReducerClass = Class.forName(reducerClass).getClass();	// WordCount$IntSumReducer
			//System.out.println("Reducer class loaded:: " + ReducerClass.getName());
			
			BufferedReader reader = new BufferedReader(new FileReader(keyFileName));
			//System.out.println("Fetching Reducer input from: " + keyFileName);
			String ipLine = reader.readLine().replaceAll("\\s+", " ");
			reader.close();
			String[] stringVals = ipLine.split(" ");
			
			for(String val : stringVals)
			{
				// TODO generalization
				IntWritable finalVal = new IntWritable(Integer.parseInt(val));
				valList.add(finalVal);
			}
				
			Reducer<KEYIN, VALUEIN, KEYOUT, VALUEOUT> obj = (Reducer<KEYIN, VALUEIN, KEYOUT, VALUEOUT>)Class.forName(reducerClass).newInstance();
			// TODO generalization
			//System.out.println("Reducer class loaded:: " + obj.getClass());
			obj.reduce( new Text(key), (Iterable<VALUEIN>)valList, context);
				
			// Clearing up the output file for the reducer output
			//BufferedWriter writer = new BufferedWriter(new FileWriter(tmpFile));
			//writer.write("");
			//writer.close();
				      
		} catch (Exception e) 
        {
			e.printStackTrace();
		}  
	}
	
}
